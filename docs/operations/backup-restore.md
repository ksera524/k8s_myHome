# ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ãƒªã‚¹ãƒˆã‚¢ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

k8s_myHomeã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚¹ãƒˆã‚¢æ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚æœ¬ç•ªç’°å¢ƒã§ã®é‹ç”¨ã‚’æƒ³å®šã—ã€RPOï¼ˆRecovery Point Objectiveï¼‰ã¨RTOï¼ˆRecovery Time Objectiveï¼‰ã‚’è€ƒæ…®ã—ãŸè¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™ã€‚

## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ã¨å„ªå…ˆåº¦

| å„ªå…ˆåº¦ | å¯¾è±¡ | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é »åº¦ | ä¿æŒæœŸé–“ | RPO |
|-------|------|-----------------|----------|-----|
| **Critical** | etcd ãƒ‡ãƒ¼ã‚¿ | æ—¥æ¬¡ | 30æ—¥ | 24æ™‚é–“ |
| **Critical** | PersistentVolumes | æ—¥æ¬¡ | 30æ—¥ | 24æ™‚é–“ |
| **High** | Kubernetesè¨­å®š | é€±æ¬¡ | 90æ—¥ | 7æ—¥ |
| **High** | VM ã‚¤ãƒ¡ãƒ¼ã‚¸ | é€±æ¬¡ | 30æ—¥ | 7æ—¥ |
| **Medium** | Harbor ãƒ¬ã‚¸ã‚¹ãƒˆãƒª | æ—¥æ¬¡ | 14æ—¥ | 24æ™‚é–“ |
| **Medium** | ArgoCD è¨­å®š | å¤‰æ›´æ™‚ | æ°¸ç¶š | Gitç®¡ç† |
| **Low** | ãƒ­ã‚°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | æ—¥æ¬¡ | 7æ—¥ | 24æ™‚é–“ |

## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè£…

### 1. è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# /usr/local/bin/k8s-backup.sh

set -e

# è¨­å®š
BACKUP_DIR="/backup/k8s_myHome"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_PATH="${BACKUP_DIR}/${DATE}"
RETENTION_DAYS=30

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "${BACKUP_PATH}"

# ãƒ­ã‚°é–¢æ•°
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "${BACKUP_PATH}/backup.log"
}

log "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹: ${DATE}"

# 1. etcdãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
backup_etcd() {
    log "etcdãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹..."
    
    ssh k8suser@192.168.122.10 "
        sudo ETCDCTL_API=3 etcdctl \
            --endpoints=https://127.0.0.1:2379 \
            --cacert=/etc/kubernetes/pki/etcd/ca.crt \
            --cert=/etc/kubernetes/pki/etcd/server.crt \
            --key=/etc/kubernetes/pki/etcd/server.key \
            snapshot save /tmp/etcd-snapshot-${DATE}.db
    "
    
    scp k8suser@192.168.122.10:/tmp/etcd-snapshot-${DATE}.db \
        "${BACKUP_PATH}/etcd-snapshot.db"
    
    ssh k8suser@192.168.122.10 "rm /tmp/etcd-snapshot-${DATE}.db"
    
    log "etcdãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
}

# 2. Kubernetesè¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
backup_k8s_config() {
    log "Kubernetesè¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹..."
    
    # é‡è¦ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    ssh k8suser@192.168.122.10 "
        sudo tar czf /tmp/k8s-config-${DATE}.tar.gz \
            /etc/kubernetes/ \
            /var/lib/kubelet/config.yaml \
            /etc/cni/
    "
    
    scp k8suser@192.168.122.10:/tmp/k8s-config-${DATE}.tar.gz \
        "${BACKUP_PATH}/k8s-config.tar.gz"
    
    ssh k8suser@192.168.122.10 "rm /tmp/k8s-config-${DATE}.tar.gz"
    
    log "Kubernetesè¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
}

# 3. ãƒªã‚½ãƒ¼ã‚¹å®šç¾©ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
backup_resources() {
    log "ãƒªã‚½ãƒ¼ã‚¹å®šç¾©ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹..."
    
    # ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’YAMLã§ä¿å­˜
    kubectl get all,cm,secret,pv,pvc,ingress,crd \
        --all-namespaces \
        -o yaml > "${BACKUP_PATH}/all-resources.yaml"
    
    # Namespaceåˆ¥ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    for ns in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
        mkdir -p "${BACKUP_PATH}/namespaces/${ns}"
        kubectl get all,cm,secret,pvc,ingress \
            -n "${ns}" \
            -o yaml > "${BACKUP_PATH}/namespaces/${ns}/resources.yaml"
    done
    
    log "ãƒªã‚½ãƒ¼ã‚¹å®šç¾©ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
}

# 4. PersistentVolumeãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
backup_pv_data() {
    log "PVãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹..."
    
    # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰ã®PVãƒ‡ãƒ¼ã‚¿
    for node in 192.168.122.11 192.168.122.12; do
        ssh k8suser@${node} "
            sudo tar czf /tmp/pv-data-${DATE}.tar.gz \
                /opt/local-path-provisioner/
        " || true
        
        scp k8suser@${node}:/tmp/pv-data-${DATE}.tar.gz \
            "${BACKUP_PATH}/pv-data-$(echo $node | cut -d. -f4).tar.gz" || true
        
        ssh k8suser@${node} "rm -f /tmp/pv-data-${DATE}.tar.gz" || true
    done
    
    log "PVãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
}

# 5. Harbor ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
backup_harbor() {
    log "Harborãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹..."
    
    # Harbor ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ€ãƒ³ãƒ—
    kubectl exec -n harbor \
        $(kubectl get pod -n harbor -l component=database -o jsonpath='{.items[0].metadata.name}') \
        -- pg_dump -U postgres registry > "${BACKUP_PATH}/harbor-db.sql"
    
    # Harbor è¨­å®š
    kubectl get cm,secret -n harbor -o yaml > "${BACKUP_PATH}/harbor-config.yaml"
    
    log "Harborãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
}

# 6. VM ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
backup_vms() {
    log "VMã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆé–‹å§‹..."
    
    for vm in k8s-control-plane-1 k8s-worker-1 k8s-worker-2; do
        sudo virsh snapshot-create-as ${vm} \
            --name "backup-${DATE}" \
            --description "Automated backup ${DATE}" \
            --disk-only \
            --atomic
    done
    
    log "VMã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå®Œäº†"
}

# å®Ÿè¡Œ
backup_etcd
backup_k8s_config
backup_resources
backup_pv_data
backup_harbor
backup_vms

# åœ§ç¸®
log "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—åœ§ç¸®ä¸­..."
cd "${BACKUP_DIR}"
tar czf "${DATE}.tar.gz" "${DATE}/"
rm -rf "${DATE}/"

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
log "å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ä¸­..."
find "${BACKUP_DIR}" -name "*.tar.gz" -mtime +${RETENTION_DAYS} -delete

log "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: ${BACKUP_PATH}.tar.gz"
```

### 2. Cronã‚¸ãƒ§ãƒ–è¨­å®š

```bash
# crontab -e
# æ¯æ—¥åˆå‰2æ™‚ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
0 2 * * * /usr/local/bin/k8s-backup.sh >> /var/log/k8s-backup.log 2>&1

# é€±æ¬¡ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ—¥æ›œæ—¥åˆå‰3æ™‚ï¼‰
0 3 * * 0 /usr/local/bin/k8s-full-backup.sh >> /var/log/k8s-backup.log 2>&1
```

### 3. Kubernetes CronJobã«ã‚ˆã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etcd-backup
  namespace: kube-system
spec:
  schedule: "0 2 * * *"  # æ¯æ—¥åˆå‰2æ™‚
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: k8s.gcr.io/etcd:3.5.9-0
            command:
            - /bin/sh
            - -c
            - |
              etcdctl --endpoints=https://etcd-0:2379 \
                --cacert=/etc/kubernetes/pki/etcd/ca.crt \
                --cert=/etc/kubernetes/pki/etcd/server.crt \
                --key=/etc/kubernetes/pki/etcd/server.key \
                snapshot save /backup/etcd-$(date +%Y%m%d-%H%M%S).db
            volumeMounts:
            - name: etcd-certs
              mountPath: /etc/kubernetes/pki/etcd
            - name: backup
              mountPath: /backup
          volumes:
          - name: etcd-certs
            hostPath:
              path: /etc/kubernetes/pki/etcd
          - name: backup
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
          nodeSelector:
            node-role.kubernetes.io/control-plane: "true"
          tolerations:
          - key: node-role.kubernetes.io/control-plane
            operator: Exists
            effect: NoSchedule
```

## ãƒªã‚¹ãƒˆã‚¢æ‰‹é †

### 1. å®Œå…¨ãƒªã‚¹ãƒˆã‚¢ï¼ˆç½å®³å¾©æ—§ï¼‰

```bash
#!/bin/bash
# /usr/local/bin/k8s-restore.sh

set -e

# è¨­å®š
BACKUP_FILE=$1
RESTORE_DIR="/tmp/restore"

if [ -z "$BACKUP_FILE" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <backup-file.tar.gz>"
    exit 1
fi

# ãƒ­ã‚°é–¢æ•°
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

log "ãƒªã‚¹ãƒˆã‚¢é–‹å§‹: ${BACKUP_FILE}"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å±•é–‹
mkdir -p "${RESTORE_DIR}"
tar xzf "${BACKUP_FILE}" -C "${RESTORE_DIR}"
BACKUP_PATH=$(find "${RESTORE_DIR}" -mindepth 1 -maxdepth 1 -type d)

# 1. VMãƒªã‚¹ãƒˆã‚¢ï¼ˆå¿…è¦ãªå ´åˆï¼‰
restore_vms() {
    log "VMç’°å¢ƒå†ä½œæˆ..."
    
    cd /home/user/k8s_myHome/automation/infrastructure
    terraform destroy -auto-approve
    terraform apply -auto-approve
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–å¾…æ©Ÿ
    sleep 300
    
    log "VMç’°å¢ƒå†ä½œæˆå®Œäº†"
}

# 2. etcdãƒªã‚¹ãƒˆã‚¢
restore_etcd() {
    log "etcdãƒªã‚¹ãƒˆã‚¢é–‹å§‹..."
    
    # etcdã‚’åœæ­¢
    ssh k8suser@192.168.122.10 "
        sudo systemctl stop etcd
        sudo rm -rf /var/lib/etcd/member
    "
    
    # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ãƒªã‚¹ãƒˆã‚¢
    scp "${BACKUP_PATH}/etcd-snapshot.db" k8suser@192.168.122.10:/tmp/
    
    ssh k8suser@192.168.122.10 "
        sudo ETCDCTL_API=3 etcdctl snapshot restore /tmp/etcd-snapshot.db \
            --name k8s-control-plane-1 \
            --initial-cluster k8s-control-plane-1=https://192.168.122.10:2380 \
            --initial-advertise-peer-urls https://192.168.122.10:2380 \
            --data-dir /var/lib/etcd
        
        sudo chown -R etcd:etcd /var/lib/etcd
        sudo systemctl start etcd
    "
    
    log "etcdãƒªã‚¹ãƒˆã‚¢å®Œäº†"
}

# 3. Kubernetesè¨­å®šãƒªã‚¹ãƒˆã‚¢
restore_k8s_config() {
    log "Kubernetesè¨­å®šãƒªã‚¹ãƒˆã‚¢é–‹å§‹..."
    
    scp "${BACKUP_PATH}/k8s-config.tar.gz" k8suser@192.168.122.10:/tmp/
    
    ssh k8suser@192.168.122.10 "
        sudo tar xzf /tmp/k8s-config.tar.gz -C /
        sudo systemctl restart kubelet
    "
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰ã‚‚åŒæ§˜ã«
    for node in 192.168.122.11 192.168.122.12; do
        scp "${BACKUP_PATH}/k8s-config.tar.gz" k8suser@${node}:/tmp/
        ssh k8suser@${node} "
            sudo tar xzf /tmp/k8s-config.tar.gz -C / --exclude='pki/*'
            sudo systemctl restart kubelet
        "
    done
    
    log "Kubernetesè¨­å®šãƒªã‚¹ãƒˆã‚¢å®Œäº†"
}

# 4. PVãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚¢
restore_pv_data() {
    log "PVãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚¢é–‹å§‹..."
    
    for i in 1 2; do
        node_ip="192.168.122.1${i}"
        if [ -f "${BACKUP_PATH}/pv-data-${i}.tar.gz" ]; then
            scp "${BACKUP_PATH}/pv-data-${i}.tar.gz" k8suser@${node_ip}:/tmp/
            ssh k8suser@${node_ip} "
                sudo tar xzf /tmp/pv-data-${i}.tar.gz -C /
            "
        fi
    done
    
    log "PVãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚¢å®Œäº†"
}

# 5. ãƒªã‚½ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚¢
restore_resources() {
    log "ãƒªã‚½ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚¢é–‹å§‹..."
    
    # CRDã‹ã‚‰å…ˆã«ãƒªã‚¹ãƒˆã‚¢
    kubectl apply -f "${BACKUP_PATH}/all-resources.yaml" \
        --dry-run=client -o yaml | \
        grep -A 1000 "kind: CustomResourceDefinition" | \
        kubectl apply -f -
    
    # ãã®ä»–ã®ãƒªã‚½ãƒ¼ã‚¹
    kubectl apply -f "${BACKUP_PATH}/all-resources.yaml" \
        --dry-run=client -o yaml | \
        kubectl apply -f -
    
    log "ãƒªã‚½ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚¢å®Œäº†"
}

# å®Ÿè¡Œç¢ºèª
read -p "ãƒªã‚¹ãƒˆã‚¢ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ [y/N]: " confirm
if [ "$confirm" != "y" ]; then
    echo "ä¸­æ­¢ã—ã¾ã—ãŸ"
    exit 0
fi

# ãƒªã‚¹ãƒˆã‚¢å®Ÿè¡Œ
restore_etcd
restore_k8s_config
restore_pv_data
restore_resources

log "ãƒªã‚¹ãƒˆã‚¢å®Œäº†"
```

### 2. éƒ¨åˆ†ãƒªã‚¹ãƒˆã‚¢

#### ç‰¹å®šNamespaceã®ãƒªã‚¹ãƒˆã‚¢
```bash
# Namespaceå˜ä½ã§ãƒªã‚¹ãƒˆã‚¢
kubectl apply -f /backup/namespaces/harbor/resources.yaml
```

#### ç‰¹å®šã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒªã‚¹ãƒˆã‚¢
```bash
# Deploymentã¨ãã®é–¢é€£ãƒªã‚½ãƒ¼ã‚¹
kubectl apply -f - <<EOF
$(grep -A 50 "name: my-app" /backup/all-resources.yaml)
EOF
```

#### PVCãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒªã‚¹ãƒˆã‚¢
```bash
# ç‰¹å®šPVCã®ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚¢
PVC_NAME="harbor-database"
NODE_IP=$(kubectl get pv $(kubectl get pvc ${PVC_NAME} -o jsonpath='{.spec.volumeName}') \
    -o jsonpath='{.spec.nodeAffinity.required.nodeSelectorTerms[0].matchExpressions[0].values[0]}')

ssh k8suser@${NODE_IP} "
    sudo tar xzf /backup/pv-data.tar.gz \
        -C / \
        opt/local-path-provisioner/pvc-*${PVC_NAME}*
"
```

## ãƒªã‚¹ãƒˆã‚¢æ¤œè¨¼

### 1. æ¤œè¨¼ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```bash
#!/bin/bash
# ãƒªã‚¹ãƒˆã‚¢å¾Œã®æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

echo "=== ãƒªã‚¹ãƒˆã‚¢æ¤œè¨¼ ==="

# 1. ãƒãƒ¼ãƒ‰çŠ¶æ…‹
echo "1. ãƒãƒ¼ãƒ‰çŠ¶æ…‹ç¢ºèª"
kubectl get nodes
echo ""

# 2. ã‚·ã‚¹ãƒ†ãƒ Pod
echo "2. ã‚·ã‚¹ãƒ†ãƒ Podç¢ºèª"
kubectl get pods -n kube-system
echo ""

# 3. etcdå¥å…¨æ€§
echo "3. etcdå¥å…¨æ€§ç¢ºèª"
kubectl exec -n kube-system etcd-k8s-control-plane-1 -- \
    etcdctl --endpoints=https://127.0.0.1:2379 \
    --cacert=/etc/kubernetes/pki/etcd/ca.crt \
    --cert=/etc/kubernetes/pki/etcd/server.crt \
    --key=/etc/kubernetes/pki/etcd/server.key \
    endpoint health
echo ""

# 4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
echo "4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹"
kubectl get deployments --all-namespaces
echo ""

# 5. PVC
echo "5. PVCçŠ¶æ…‹"
kubectl get pvc --all-namespaces
echo ""

# 6. ã‚µãƒ¼ãƒ“ã‚¹ç–é€š
echo "6. ã‚µãƒ¼ãƒ“ã‚¹ç–é€šç¢ºèª"
kubectl get svc --all-namespaces | grep LoadBalancer
echo ""

echo "=== æ¤œè¨¼å®Œäº† ==="
```

### 2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‹•ä½œç¢ºèª

```bash
# ArgoCD
kubectl port-forward svc/argocd-server -n argocd 8080:443
# ãƒ–ãƒ©ã‚¦ã‚¶ã§ https://localhost:8080 ã‚¢ã‚¯ã‚»ã‚¹

# Harbor
curl -I http://192.168.122.100

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
for app in $(kubectl get ingress --all-namespaces -o jsonpath='{.items[*].spec.rules[*].host}'); do
    echo "Testing: $app"
    curl -I https://$app
done
```

## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. 3-2-1ãƒ«ãƒ¼ãƒ«
- **3ã¤**ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚³ãƒ”ãƒ¼
- **2ã¤**ã®ç•°ãªã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢
- **1ã¤**ã®ã‚ªãƒ•ã‚µã‚¤ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

### 2. å®šæœŸãƒ†ã‚¹ãƒˆ
```yaml
# æœˆæ¬¡ãƒªã‚¹ãƒˆã‚¢ãƒ†ã‚¹ãƒˆ
apiVersion: batch/v1
kind: CronJob
metadata:
  name: restore-test
spec:
  schedule: "0 0 1 * *"  # æ¯æœˆ1æ—¥
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: test
            image: busybox
            command: ["/bin/sh", "-c", "echo 'Restore test reminder'"]
```

### 3. ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
```yaml
# Prometheusã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
groups:
- name: backup
  rules:
  - alert: BackupFailed
    expr: backup_last_success_timestamp < time() - 86400
    for: 1h
    annotations:
      summary: "Backup has not succeeded in 24 hours"
  
  - alert: BackupStorageFull
    expr: backup_storage_usage_percent > 90
    for: 30m
    annotations:
      summary: "Backup storage is over 90% full"
```

## ç½å®³å¾©æ—§ã‚·ãƒŠãƒªã‚ª

### ã‚·ãƒŠãƒªã‚ª1: ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ãƒ¼ãƒ³éšœå®³
```bash
# 1. å½±éŸ¿ç¢ºèª
kubectl get nodes

# 2. etcdãƒ¡ãƒ³ãƒãƒ¼ç¢ºèª
etcdctl member list

# 3. æ–°ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ãƒ¼ãƒ³è¿½åŠ 
kubeadm join --control-plane

# 4. etcdãƒªã‚¹ãƒˆã‚¢ï¼ˆå¿…è¦ãªå ´åˆï¼‰
./k8s-restore.sh etcd-only
```

### ã‚·ãƒŠãƒªã‚ª2: å®Œå…¨éšœå®³
```bash
# 1. ã‚¤ãƒ³ãƒ•ãƒ©å†æ§‹ç¯‰
cd automation/infrastructure
terraform apply

# 2. ãƒ•ãƒ«ãƒªã‚¹ãƒˆã‚¢
./k8s-restore.sh /backup/latest.tar.gz

# 3. æ¤œè¨¼
./verify-restore.sh
```

### ã‚·ãƒŠãƒªã‚ª3: ãƒ‡ãƒ¼ã‚¿ç ´æ
```bash
# 1. å½±éŸ¿ç¯„å›²ç‰¹å®š
kubectl get events --all-namespaces

# 2. éƒ¨åˆ†ãƒªã‚¹ãƒˆã‚¢
./k8s-restore.sh --partial --namespace affected-namespace

# 3. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª
kubectl exec -n affected-namespace -- app-health-check
```

---
*æœ€çµ‚æ›´æ–°: 2025-01-09*