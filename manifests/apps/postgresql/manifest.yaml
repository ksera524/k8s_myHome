# PostgreSQLバックアップ設定（RustFS/S3互換）
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql-backup-config
  namespace: database
data:
  S3_ENDPOINT: http://rustfs-svc.rustfs.svc:9000
  S3_BUCKET: postgresql-backups
  RETENTION_DAYS: "7"
  PGHOST: postgresql
  PGPORT: "5432"
  PGUSER: postgres
  PGDATABASE: app

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgresql-backup
  namespace: database
spec:
  schedule: "0 2 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 2
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: backup
              image: postgres:16-alpine
              imagePullPolicy: IfNotPresent
              envFrom:
                - configMapRef:
                    name: postgresql-backup-config
              env:
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: postgresql-auth
                      key: postgres-password
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: rustfs-backup-auth
                      key: RUSTFS_ACCESS_KEY
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: rustfs-backup-auth
                      key: RUSTFS_SECRET_KEY
              command:
                - /bin/sh
                - -c
                - |
                  set -eu
                  set -o pipefail
                  apk add --no-cache aws-cli coreutils
                  timestamp=$(date -u +"%Y%m%dT%H%M%SZ")
                  backup_file="postgresql-${timestamp}.sql.gz"
                  pg_dump --no-owner --no-acl | gzip > "/tmp/${backup_file}"
                  aws --endpoint-url "${S3_ENDPOINT}" s3 cp "/tmp/${backup_file}" "s3://${S3_BUCKET}/${backup_file}"
                  cutoff_ts=$(date -u -d "-${RETENTION_DAYS} days" +%s)
                  aws --endpoint-url "${S3_ENDPOINT}" s3 ls "s3://${S3_BUCKET}/" | while read -r date time size key; do
                    [ -z "${key:-}" ] && continue
                    obj_ts=$(date -u -d "${date} ${time}" +%s)
                    if [ "${obj_ts}" -lt "${cutoff_ts}" ]; then
                      aws --endpoint-url "${S3_ENDPOINT}" s3 rm "s3://${S3_BUCKET}/${key}"
                    fi
                  done
