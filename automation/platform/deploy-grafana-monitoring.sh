#!/bin/bash

# Grafana k8s-monitoring ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# External SecretsçµŒç”±ã§Grafana Cloudèªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤

set -euo pipefail

# è‰²è¨­å®š
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

log_status() { echo -e "${GREEN}$1${NC}"; }
log_error() { echo -e "${RED}$1${NC}"; }
log_warning() { echo -e "${YELLOW}$1${NC}"; }

# IPã‚¢ãƒ‰ãƒ¬ã‚¹è¨­å®š
CONTROL_PLANE_IP="${K8S_CONTROL_PLANE_IP:-192.168.122.10}"

log_status "=== Grafana k8s-monitoring ãƒ‡ãƒ—ãƒ­ã‚¤é–‹å§‹ ==="

# å‰ææ¡ä»¶ç¢ºèª
log_status "å‰ææ¡ä»¶ã‚’ç¢ºèªä¸­..."

# k8sã‚¯ãƒ©ã‚¹ã‚¿æ¥ç¶šç¢ºèª
if ! ssh -T -o StrictHostKeyChecking=no -o BatchMode=yes -o LogLevel=ERROR -o ConnectTimeout=10 k8suser@${CONTROL_PLANE_IP} 'kubectl get nodes' >/dev/null 2>&1; then
    log_error "k8sã‚¯ãƒ©ã‚¹ã‚¿ã«æ¥ç¶šã§ãã¾ã›ã‚“"
    exit 1
fi

# External Secrets Operatorç¢ºèª
ssh -T -o StrictHostKeyChecking=no -o BatchMode=yes -o LogLevel=ERROR k8suser@${CONTROL_PLANE_IP} << 'EOF'
echo "External Secrets Operatorç¢ºèªä¸­..."
if ! kubectl get deployment -n external-secrets-system external-secrets-operator >/dev/null 2>&1; then
    echo "ã‚¨ãƒ©ãƒ¼: External Secrets OperatorãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
    exit 1
fi

# ClusterSecretStoreç¢ºèª
if ! kubectl get clustersecretstore pulumi-esc-store >/dev/null 2>&1; then
    echo "ã‚¨ãƒ©ãƒ¼: ClusterSecretStore pulumi-esc-storeãŒå­˜åœ¨ã—ã¾ã›ã‚“"
    exit 1
fi

echo "âœ“ External Secrets Operatoræº–å‚™å®Œäº†"
EOF

# External Secret ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼
log_status "External Secret ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’é©ç”¨ä¸­..."
scp -o StrictHostKeyChecking=no ../../manifests/config/secrets/grafana-monitoring-externalsecret.yaml k8suser@${CONTROL_PLANE_IP}:/tmp/

# External Secreté©ç”¨ã¨Secretä½œæˆå¾…æ©Ÿ
ssh -T -o StrictHostKeyChecking=no -o BatchMode=yes -o LogLevel=ERROR k8suser@${CONTROL_PLANE_IP} << 'EOF'
# monitoring namespaceä½œæˆ
kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

# External Secreté©ç”¨
kubectl apply -f /tmp/grafana-monitoring-externalsecret.yaml

# Secretä½œæˆå¾…æ©Ÿ
echo "Grafana Cloudèªè¨¼æƒ…å ±ã®åŒæœŸå¾…æ©Ÿä¸­..."
for i in {1..30}; do
    if kubectl get secret grafana-cloud-monitoring -n monitoring >/dev/null 2>&1; then
        echo "âœ“ Grafana Cloudèªè¨¼æƒ…å ±å–å¾—å®Œäº†"
        break
    fi
    echo "SecretåŒæœŸå¾…æ©Ÿä¸­... ($i/30)"
    sleep 5
done

# Secretå­˜åœ¨ç¢ºèª
if ! kubectl get secret grafana-cloud-monitoring -n monitoring >/dev/null 2>&1; then
    echo "ã‚¨ãƒ©ãƒ¼: Grafana Cloudèªè¨¼æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    echo "Pulumi ESCã« 'grafana' ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
    exit 1
fi

# èªè¨¼æƒ…å ±å–å¾—ï¼ˆAPI Tokenã®ã¿ï¼‰
API_TOKEN=$(kubectl get secret grafana-cloud-monitoring -n monitoring -o jsonpath='{.data.api-token}' | base64 -d)

if [[ -z "$API_TOKEN" ]]; then
    echo "ã‚¨ãƒ©ãƒ¼: API Tokenã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    exit 1
fi

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯å›ºå®šå€¤
METRICS_USERNAME="2666273"
LOGS_USERNAME="1328813"
OTLP_USERNAME="1371019"

echo "âœ“ èªè¨¼æƒ…å ±å–å¾—å®Œäº†"
EOF

# Grafana k8s-monitoring values ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
log_status "Grafana k8s-monitoring values ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­..."
ssh -T -o StrictHostKeyChecking=no -o BatchMode=yes -o LogLevel=ERROR k8suser@${CONTROL_PLANE_IP} << 'EOF'
# èªè¨¼æƒ…å ±å–å¾—ï¼ˆAPI Tokenã®ã¿ï¼‰
API_TOKEN=$(kubectl get secret grafana-cloud-monitoring -n monitoring -o jsonpath='{.data.api-token}' | base64 -d)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯å›ºå®šå€¤
METRICS_USERNAME="2666273"
LOGS_USERNAME="1328813"
OTLP_USERNAME="1371019"

# Values ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
cat > /tmp/grafana-k8s-monitoring-values.yaml << VALUES_EOF
cluster:
  name: k8s-myhome
destinations:
  - name: grafana-cloud-metrics
    type: prometheus
    url: https://prometheus-prod-49-prod-ap-northeast-0.grafana.net/api/prom/push
    auth:
      type: basic
      username: "${METRICS_USERNAME}"
      password: ${API_TOKEN}
  - name: grafana-cloud-logs
    type: loki
    url: https://logs-prod-030.grafana.net/loki/api/v1/push
    auth:
      type: basic
      username: "${LOGS_USERNAME}"
      password: ${API_TOKEN}
  - name: gc-otlp-endpoint
    type: otlp
    url: https://otlp-gateway-prod-ap-northeast-0.grafana.net/otlp
    protocol: http
    auth:
      type: basic
      username: "${OTLP_USERNAME}"
      password: ${API_TOKEN}
    metrics:
      enabled: true
    logs:
      enabled: true
    traces:
      enabled: true
clusterMetrics:
  enabled: true
  opencost:
    enabled: true
    metricsSource: grafana-cloud-metrics
    opencost:
      exporter:
        defaultClusterId: k8s-myhome
      prometheus:
        existingSecretName: grafana-cloud-metrics-grafana-k8s-monitoring
        external:
          url: https://prometheus-prod-49-prod-ap-northeast-0.grafana.net/api/prom
  kepler:
    enabled: false  # VMç’°å¢ƒã§ã¯å‹•ä½œã—ãªã„
clusterEvents:
  enabled: true
podLogs:
  enabled: true
applicationObservability:
  enabled: true
  receivers:
    otlp:
      grpc:
        enabled: true
        port: 4317
      http:
        enabled: true
        port: 4318
    zipkin:
      enabled: true
      port: 9411
alloy-metrics:
  enabled: true
  alloy:
    extraEnv:
      - name: GCLOUD_RW_API_KEY
        valueFrom:
          secretKeyRef:
            name: grafana-cloud-monitoring
            key: api-token
      - name: CLUSTER_NAME
        value: k8s-myhome
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: GCLOUD_FM_COLLECTOR_ID
        value: grafana-k8s-monitoring-\$(CLUSTER_NAME)-\$(NAMESPACE)-\$(POD_NAME)
  remoteConfig:
    enabled: true
    url: https://fleet-management-prod-019.grafana.net
    auth:
      type: existingSecret
      existingSecretName: grafana-cloud-monitoring
      existingSecretUsernameKey: otlp-username
      existingSecretPasswordKey: api-token
alloy-singleton:
  enabled: true
  alloy:
    extraEnv:
      - name: GCLOUD_RW_API_KEY
        valueFrom:
          secretKeyRef:
            name: grafana-cloud-monitoring
            key: api-token
      - name: CLUSTER_NAME
        value: k8s-myhome
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: GCLOUD_FM_COLLECTOR_ID
        value: grafana-k8s-monitoring-\$(CLUSTER_NAME)-\$(NAMESPACE)-\$(POD_NAME)
  remoteConfig:
    enabled: true
    url: https://fleet-management-prod-019.grafana.net
    auth:
      type: existingSecret
      existingSecretName: grafana-cloud-monitoring
      existingSecretUsernameKey: otlp-username
      existingSecretPasswordKey: api-token
alloy-logs:
  enabled: true
  alloy:
    extraEnv:
      - name: GCLOUD_RW_API_KEY
        valueFrom:
          secretKeyRef:
            name: grafana-cloud-monitoring
            key: api-token
      - name: CLUSTER_NAME
        value: k8s-myhome
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
      - name: GCLOUD_FM_COLLECTOR_ID
        value: grafana-k8s-monitoring-\$(CLUSTER_NAME)-\$(NAMESPACE)-alloy-logs-\$(NODE_NAME)
  remoteConfig:
    enabled: true
    url: https://fleet-management-prod-019.grafana.net
    auth:
      type: existingSecret
      existingSecretName: grafana-cloud-monitoring
      existingSecretUsernameKey: otlp-username
      existingSecretPasswordKey: api-token
alloy-receiver:
  enabled: true
  alloy:
    extraPorts:
      - name: otlp-grpc
        port: 4317
        targetPort: 4317
        protocol: TCP
      - name: otlp-http
        port: 4318
        targetPort: 4318
        protocol: TCP
      - name: zipkin
        port: 9411
        targetPort: 9411
        protocol: TCP
    extraEnv:
      - name: GCLOUD_RW_API_KEY
        valueFrom:
          secretKeyRef:
            name: grafana-cloud-monitoring
            key: api-token
      - name: CLUSTER_NAME
        value: k8s-myhome
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
      - name: GCLOUD_FM_COLLECTOR_ID
        value: grafana-k8s-monitoring-\$(CLUSTER_NAME)-\$(NAMESPACE)-alloy-receiver-\$(NODE_NAME)
  remoteConfig:
    enabled: true
    url: https://fleet-management-prod-019.grafana.net
    auth:
      type: existingSecret
      existingSecretName: grafana-cloud-monitoring
      existingSecretUsernameKey: otlp-username
      existingSecretPasswordKey: api-token
VALUES_EOF

echo "âœ“ Values ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†"
EOF

# Helm ãƒªãƒã‚¸ãƒˆãƒªè¿½åŠ ã¨ãƒ‡ãƒ—ãƒ­ã‚¤
log_status "Grafana k8s-monitoring ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ä¸­..."
ssh -T -o StrictHostKeyChecking=no -o BatchMode=yes -o LogLevel=ERROR k8suser@${CONTROL_PLANE_IP} << 'EOF'
# Helm ãƒªãƒã‚¸ãƒˆãƒªè¿½åŠ 
helm repo add grafana https://grafana.github.io/helm-charts 2>/dev/null || true
helm repo update

# Grafana k8s-monitoring ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo "Grafana k8s-monitoring Helm chart ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
helm upgrade --install grafana-k8s-monitoring grafana/k8s-monitoring \
  --namespace monitoring \
  -f /tmp/grafana-k8s-monitoring-values.yaml \
  --timeout 10m \
  --wait || echo "Grafana k8s-monitoring ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¶™ç¶šä¸­..."

# Pod ã®èµ·å‹•ã‚’å¾…æ©Ÿ
echo "Grafana k8s-monitoring Pod èµ·å‹•å¾…æ©Ÿä¸­..."
sleep 30

# Pod ã®çŠ¶æ…‹ç¢ºèª
echo "Grafana k8s-monitoring Pod çŠ¶æ…‹:"
kubectl get pods -n monitoring

# ã™ã¹ã¦ã® Pod ãŒ Running ã«ãªã‚‹ã¾ã§å¾…æ©Ÿï¼ˆæœ€å¤§3åˆ†ï¼‰
for i in {1..18}; do
    PENDING_PODS=$(kubectl get pods -n monitoring --no-headers 2>/dev/null | grep -v Running | wc -l || echo "0")
    if [ "$PENDING_PODS" -eq "0" ]; then
        echo "âœ“ ã™ã¹ã¦ã® Grafana k8s-monitoring Pod ãŒèµ·å‹•ã—ã¾ã—ãŸ"
        break
    fi
    echo "Pod èµ·å‹•å¾…æ©Ÿä¸­... (æ®‹ã‚Š Pending: $PENDING_PODS)"
    sleep 10
done

echo "âœ“ Grafana k8s-monitoring ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†"
echo ""
echo "ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:"
echo "  - kube-state-metrics: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"
echo "  - Node Exporter: ãƒãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"
echo "  - Alloy metrics: ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ»é€ä¿¡"
echo "  - Alloy logs: ãƒ­ã‚°åé›†ãƒ»é€ä¿¡"
echo "  - Alloy singleton: ã‚¤ãƒ™ãƒ³ãƒˆåé›†"
echo "  - Alloy receiver: OTLP/Zipkinãƒˆãƒ¬ãƒ¼ã‚¹å—ä¿¡"
echo "  - OpenCost: ã‚³ã‚¹ãƒˆåˆ†æ"
echo ""
echo "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªãƒ¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:"
echo "  - OTLP gRPC: http://grafana-k8s-monitoring-alloy-receiver.monitoring.svc.cluster.local:4317"
echo "  - OTLP HTTP: http://grafana-k8s-monitoring-alloy-receiver.monitoring.svc.cluster.local:4318"
echo "  - Zipkin: http://grafana-k8s-monitoring-alloy-receiver.monitoring.svc.cluster.local:9411"
EOF

log_status "âœ“ Grafana k8s-monitoring ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†"
log_status ""
log_status "ğŸ‰ Grafana Cloud ã¸ã®ç›£è¦–æ©Ÿèƒ½ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸï¼"
log_status "Grafana Cloud ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒ­ã‚°ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„"