# Phase 3: k8sæ§‹ç¯‰ï¼ˆAnsibleï¼‰

kubeadmã‚’ä½¿ç”¨ã—ã¦Control Plane 1å° + Worker Node 2å°ã®k8sã‚¯ãƒ©ã‚¹ã‚¿ã‚’è‡ªå‹•æ§‹ç¯‰ã—ã¾ã™ã€‚

## æ¦‚è¦

Phase 2ã§æ§‹ç¯‰ã•ã‚ŒãŸVMç’°å¢ƒã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®k8sã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»è¨­å®šã—ã¾ã™ï¼š

- **kubeadm cluster**: Control Plane + Worker Node 2å°
- **Container Runtime**: containerd (systemd cgroupå¯¾å¿œ)
- **CNI**: Flannel (Podé–“é€šä¿¡)
- **kubectl**: ç®¡ç†ã‚³ãƒãƒ³ãƒ‰è¨­å®š

## å‰ææ¡ä»¶

Phase 2ã®VMæ§‹ç¯‰ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼š

```bash
# VMçŠ¶æ…‹ç¢ºèª
sudo virsh list --all

# SSHæ¥ç¶šç¢ºèª
ssh k8suser@192.168.122.10 'hostname && sudo cloud-init status'
ssh k8suser@192.168.122.11 'hostname && sudo cloud-init status'
ssh k8suser@192.168.122.12 'hostname && sudo cloud-init status'
```

## ğŸš€ å®Ÿè¡Œæ–¹æ³•

### ãƒ¯ãƒ³ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰

```bash
# k8sã‚¯ãƒ©ã‚¹ã‚¿è‡ªå‹•æ§‹ç¯‰
./k8s-deploy.sh
```

### æ‰‹å‹•å®Ÿè¡Œ

```bash
# 1. Ansibleæ¥ç¶šãƒ†ã‚¹ãƒˆ
ansible -i inventory.ini all -m ping

# 2. k8sã‚¯ãƒ©ã‚¹ã‚¿æ§‹ç¯‰å®Ÿè¡Œ
ansible-playbook -i inventory.ini k8s-setup.yml

# 3. æ§‹ç¯‰çµæœç¢ºèª
cat k8s-cluster-info.txt
```

## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
automation/ansible/
â”œâ”€â”€ README.md              # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ inventory.ini          # Ansibleã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªï¼ˆVMæ¥ç¶šæƒ…å ±ï¼‰
â”œâ”€â”€ k8s-setup.yml         # k8sã‚¯ãƒ©ã‚¹ã‚¿æ§‹ç¯‰Playbook
â”œâ”€â”€ k8s-deploy.sh         # è‡ªå‹•å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ¨å¥¨ï¼‰
â””â”€â”€ roles/                # Ansible Rolesï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
```

## æ§‹ç¯‰å†…å®¹

### Phase 3.1: Control PlaneåˆæœŸåŒ–
- containerdè¨­å®šï¼ˆsystemd cgroupæœ‰åŠ¹åŒ–ï¼‰
- kubeadm initå®Ÿè¡Œ
- kubectlè¨­å®š
- Worker Nodeç”¨join-tokenç”Ÿæˆ

### Phase 3.2: Worker Nodeå‚åŠ 
- containerdè¨­å®š
- kubeadm joinã§ã‚¯ãƒ©ã‚¹ã‚¿å‚åŠ 

### Phase 3.3: CNIï¼ˆFlannelï¼‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- Flannelãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆé©ç”¨
- Podé–“é€šä¿¡ã®è¨­å®š

### Phase 3.4: ã‚¯ãƒ©ã‚¹ã‚¿çŠ¶æ…‹ç¢ºèª
- NodeçŠ¶æ…‹ç¢ºèª
- PodçŠ¶æ…‹ç¢ºèª
- æ¥ç¶šæƒ…å ±ã®ç”Ÿæˆ

## æ§‹ç¯‰å¾Œã®ç¢ºèª

### Control Plane ã§ã®ç¢ºèª

```bash
# Control Planeã«æ¥ç¶š
ssh k8suser@192.168.122.10

# ã‚¯ãƒ©ã‚¹ã‚¿çŠ¶æ…‹ç¢ºèª
kubectl get nodes -o wide
kubectl get pods --all-namespaces

# ã‚¯ãƒ©ã‚¹ã‚¿æƒ…å ±ç¢ºèª
kubectl cluster-info
```

### å¤–éƒ¨ã‹ã‚‰ã®æ¥ç¶šè¨­å®š

```bash
# kubectlè¨­å®šã‚’å¤–éƒ¨ã«å–å¾—
scp k8suser@192.168.122.10:/home/k8suser/.kube/config ~/.kube/config-k8s-cluster

# å¤–éƒ¨ã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚¿æ“ä½œ
export KUBECONFIG=~/.kube/config-k8s-cluster
kubectl get nodes
```

## æœŸå¾…ã•ã‚Œã‚‹çµæœ

### æ­£å¸¸ãªæ§‹ç¯‰å®Œäº†æ™‚

```bash
$ kubectl get nodes -o wide
NAME                STATUS   ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
k8s-control-plane   Ready    control-plane   5m    v1.29.0   192.168.122.10   <none>        Ubuntu 22.04.5 LTS   5.15.0-XXX-generic   containerd://1.7.X
k8s-worker1         Ready    <none>          3m    v1.29.0   192.168.122.11   <none>        Ubuntu 22.04.5 LTS   5.15.0-XXX-generic   containerd://1.7.X
k8s-worker2         Ready    <none>          3m    v1.29.0   192.168.122.12   <none>        Ubuntu 22.04.5 LTS   5.15.0-XXX-generic   containerd://1.7.X

$ kubectl get pods --all-namespaces
NAMESPACE      NAME                                READY   STATUS    RESTARTS   AGE
kube-flannel   kube-flannel-ds-XXX                 1/1     Running   0          2m
kube-system    coredns-XXX                         1/1     Running   0          5m
kube-system    etcd-k8s-control-plane              1/1     Running   0          5m
kube-system    kube-apiserver-k8s-control-plane    1/1     Running   0          5m
kube-system    kube-controller-manager-XXX         1/1     Running   0          5m
kube-system    kube-proxy-XXX                      1/1     Running   0          5m
kube-system    kube-scheduler-k8s-control-plane    1/1     Running   0          5m
```

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

k8sã‚¯ãƒ©ã‚¹ã‚¿æ§‹ç¯‰å®Œäº†å¾Œã¯ã€Phase 4ï¼ˆåŸºæœ¬ã‚¤ãƒ³ãƒ•ãƒ©ï¼‰ã«é€²ã¿ã¾ã™ï¼š

- MetalLBï¼ˆLoadBalancerï¼‰
- Ingress Controllerï¼ˆNGINXï¼‰
- cert-manager
- NFS StorageClass

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### æ¥ç¶šã‚¨ãƒ©ãƒ¼

```bash
# SSHæ¥ç¶šç¢ºèª
ansible -i inventory.ini all -m ping

# cloud-initå®Œäº†ç¢ºèª
ssh k8suser@192.168.122.10 'sudo cloud-init status --wait'
```

### kubeadm initå¤±æ•—

```bash
# Control Planeã§ã‚¨ãƒ©ãƒ¼ç¢ºèª
ssh k8suser@192.168.122.10 'sudo journalctl -u kubelet -f'

# kubeadmåˆæœŸåŒ–ãƒªã‚»ãƒƒãƒˆ
ssh k8suser@192.168.122.10 'sudo kubeadm reset -f'
```

### Worker Nodeå‚åŠ å¤±æ•—

```bash
# Worker Nodeã§Joinã‚³ãƒãƒ³ãƒ‰ç¢ºèª
ssh k8suser@192.168.122.11 'cat /tmp/worker-join-command.sh'

# æ‰‹å‹•ã§Joinå®Ÿè¡Œ
ssh k8suser@192.168.122.11 'sudo kubeadm reset -f && sudo bash /tmp/worker-join-command.sh'
```

### CNIï¼ˆFlannelï¼‰å•é¡Œ

```bash
# Flannel PodçŠ¶æ…‹ç¢ºèª
kubectl get pods -n kube-flannel

# Flannelå†é©ç”¨
kubectl delete -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
```

## æ‰‹å‹•æ§‹ç¯‰ï¼ˆå‚è€ƒï¼‰

Ansibleã‚’ä½¿ã‚ãªã„å ´åˆã®æ‰‹å‹•æ§‹ç¯‰æ‰‹é †ï¼š

### Control Plane

```bash
ssh k8suser@192.168.122.10

# kubeadm init
sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.122.10

# kubectlè¨­å®š
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# CNI (Flannel) ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
```

### Worker Nodes

```bash
# Control Planeã§Joinã‚³ãƒãƒ³ãƒ‰å–å¾—
kubeadm token create --print-join-command

# Worker Nodeã§å®Ÿè¡Œ
ssh k8suser@192.168.122.11
sudo [join-command]

ssh k8suser@192.168.122.12  
sudo [join-command]
```